{
 "metadata": {
  "name": "",
  "signature": "sha256:58ef83dc2e626526fd65597115a749825cc35973f48605b21b02aa79ab9f29ee"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import scipy.io\n",
      "import cPickle as pickle\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(min_df=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_lines(filename):\n",
      "    return [line.strip() for line in open(filename)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_posts = get_lines('all_posts.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = vectorizer.fit_transform(all_posts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_list_to_file(lst,filename):\n",
      "    with open(filename, 'a') as f:\n",
      "        for l in lst:\n",
      "            try:\n",
      "                f.write(\"%s\\n\" % l)\n",
      "            except:\n",
      "                f.write(' \\n') \n",
      "#                 pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(autism_vocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "122590\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "autism_vocab= vectorizer.get_feature_names()\n",
      "# print autism_vocab[100000:101000]\n",
      "write_list_to_file(autism_vocab, 'autism_vocab.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "<144368x122590 sparse matrix of type '<type 'numpy.int64'>'\n",
        "\twith 9580003 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_dok = X.todok()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_word_count(filename):\n",
      "    nonzero = X.nonzero()\n",
      "    N,M = X.shape\n",
      "    print N,M,X.nnz\n",
      "    with open(filename, 'a') as f:\n",
      "        f.write(\"%s\\n\" % str(N))\n",
      "        f.write(\"%s\\n\" % str(M))\n",
      "        f.write(\"%s\\n\" % str(X.nnz))\n",
      "        for i in range(len(nonzero[0])):\n",
      "            row = nonzero[0][i]\n",
      "            col = nonzero[1][i]\n",
      "#             try:\n",
      "            f.write(\"%s %s %s\\n\" % (row, col, X[row,col]))\n",
      "#             except:\n",
      "#                 f.write(\" \\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_word_count('autism_words.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "144368 122590 9580003\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-36-b86f8fd84f67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_word_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autism_words.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-34-d04e51b4ceb1>\u001b[0m in \u001b[0;36mget_word_count\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonzero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#             try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s %s %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#             except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#                 f.write(\" \\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jming/anaconda/lib/python2.7/site-packages/scipy/sparse/csr.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpack_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# First attempt to use original row optimized methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/jming/anaconda/lib/python2.7/site-packages/scipy/sparse/sputils.pyc\u001b[0m in \u001b[0;36m_unpack_index\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# First, check if indexing with single boolean matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m  \u001b[0;31m# This feels dirty but...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         if (isinstance(index, (spmatrix, np.ndarray)) and\n\u001b[0m\u001b[1;32m    251\u001b[0m            (index.ndim == 2) and index.dtype.kind == 'b'):\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.io.savemat('autism_words.mat', {'M': X.tolil()}, oned_as='column')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.io.savemat('autism_words_T.mat', {'M': X.transpose().tolil()}, oned_as='column')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_matrix(filename):\n",
      "\n",
      "    # return sparse.dok_matrix(sio.loadmat(filename))\n",
      "    with open(filename, 'rb') as f:\n",
      "        x = pickle.load(f)\n",
      "    return x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_sums = read_matrix('cui_sums.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_sums"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "<1321802x1321802 sparse matrix of type '<type 'numpy.float32'>'\n",
        "\twith 8812729 stored elements in Compressed Sparse Row format>"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_counter = read_matrix('cui_counter.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "<144368x1321802 sparse matrix of type '<type 'numpy.float32'>'\n",
        "\twith 2738331 stored elements in Dictionary Of Keys format>"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.io.savemat('autism_counter.mat', {'M': cui_counter.tolil()}, oned_as='column')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scipy.io.savemat('autism_counter_T.mat', {'M': cui_counter.transpose().tolil()}, oned_as='column')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_cui(in_file):\n",
      "    column_names = ['cui', 'term', 'chv_pref_name']\n",
      "    cui_df = pd.read_csv(in_file, sep='\\t', names=column_names, usecols=[0,1,2])\n",
      "    return cui_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_df = get_cui('CHV_flatfiles_all/CHV_concepts_terms_flatfile_20110204.tsv')\n",
      "print cui_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        cui                                               term  \\\n",
        "0  C0000097  1-Methyl-4-Phenyl-1,2,3,6-Tetrahydropyridine (...   \n",
        "1  C0000097                                               mptp   \n",
        "2  C0000102                                    1-naphthylamine   \n",
        "3  C0000102                                alpha-naphthylamine   \n",
        "4  C0000163                               17 hydroxycorticoids   \n",
        "\n",
        "                                  chv_pref_name  \n",
        "0  1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine  \n",
        "1  1-methyl-4-phenyl-1,2,3,6-tetrahydropyridine  \n",
        "2                               1-naphthylamine  \n",
        "3                               1-naphthylamine  \n",
        "4                     17-hydroxycorticosteroids  \n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_cui_list(cui_df):\n",
      "    \n",
      "    words = [' ' for x in range(1321802)]\n",
      "    \n",
      "    cui_sort = cui_df.sort('cui')\n",
      "    cui_grouped = cui_sort.groupby('cui')\n",
      "    \n",
      "    for name,group in cui_grouped:\n",
      "        idx = int(name[1:])\n",
      "#         print idx\n",
      "#         print group.chv_pref_name\n",
      "        if idx < 1321802:\n",
      "            words[idx] = name\n",
      "#             word = list(group['chv_pref_name'])[0]\n",
      "#             words[idx] = word.split(' ')[0]\n",
      "        \n",
      "    return words\n",
      "#         break\n",
      "#         words[int(name[1:])] = \n",
      "#     print cui_grouped.groups.keys()[:10]\n",
      "#     print cui_grouped.groups['C0220597']\n",
      "#     for i in range(1321802):\n",
      "        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_list = get_cui_list(cui_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_list_to_file(cui_list, 'autism_cui.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_list_first = get_cui_list(cui_df)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_list_to_file(cui_list_first, 'autism_cui1.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_list_cui = get_cui_list(cui_df)\n",
      "write_list_to_file(cui_list_cui, 'autism_cui2.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_cui_dict(cui_df):\n",
      "    \n",
      "    words = {}\n",
      "    \n",
      "    cui_sort = cui_df.sort('cui')\n",
      "    cui_grouped = cui_sort.groupby('cui')\n",
      "    \n",
      "    for name,group in cui_grouped:\n",
      "        words[name] = list(group['chv_pref_name'])[0]\n",
      "    \n",
      "    return words\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cui_dict = make_cui_dict(cui_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def translate_line(line, cui_dict):\n",
      "    results = []\n",
      "    line_split = line.split(' ')\n",
      "    for l in line_split:\n",
      "        try:\n",
      "            results.append(cui_dict[l])\n",
      "        except:\n",
      "            results.append(l)\n",
      "\n",
      "    return ' '.join(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "translate_line('C0452236 : C0452236 C0148405 C1095830 C0453357 C0939899 C0162751 C0679054 C0220647 C1096774 C0475332', cui_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "'cider (substance):cider (substance)vinegarapplesauce (substance)cinnamon preparationgingerchunkingcarcinoma of unknown primaryletter [publication type]flavoring'"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def translate_file(in_file, out_file):\n",
      "    contents = []\n",
      "    with (in_file, 'r') as inf:\n",
      "        with (out_file, 'w') as outf:\n",
      "            outf.write(translate_line(inf.readline()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}