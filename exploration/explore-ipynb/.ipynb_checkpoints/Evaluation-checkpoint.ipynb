{
 "metadata": {
  "name": "",
  "signature": "sha256:37418627a286166c4526a4b84b69906c5f7c0156e952ba4db4c757b304760862"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import cross_validation\n",
      "from sklearn import datasets\n",
      "from sklearn import svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.optimize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()\n",
      "iris.data.shape, iris.target.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "((150, 4), (150,))"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape, y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "((90, 4), (90,))"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape, y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "((60, 4), (60,))"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
      "clf.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf = cross_validation.KFold(20, n_folds=10)\n",
      "for train, test in kf:\n",
      "    print train,test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [0 1]\n",
        "[ 0  1  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [2 3]\n",
        "[ 0  1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [4 5]\n",
        "[ 0  1  2  3  4  5  8  9 10 11 12 13 14 15 16 17 18 19] [6 7]\n",
        "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 16 17 18 19] [8 9]\n",
        "[ 0  1  2  3  4  5  6  7  8  9 12 13 14 15 16 17 18 19] [10 11]\n",
        "[ 0  1  2  3  4  5  6  7  8  9 10 11 14 15 16 17 18 19] [12 13]\n",
        "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 16 17 18 19] [14 15]\n",
        "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18 19] [16 17]\n",
        "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17] [18 19]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "for cross-validation, just to confirm:\n",
      "\n",
      "create different folds that are separating different forum posts into training and test sets\n",
      "\n",
      "for each fold, \n",
      "take the training data and \n",
      "    build up the Q matrix, \n",
      "    choose anchors based on Arora's algorithm => A\n",
      "    and then our algorithm => A'\n",
      "then use the test data D,\n",
      "    build up the Q matrix,\n",
      "    see how many points from the test are included in the anchors proposed by A vs A' (sampling different configurations?)\n",
      "    find Z and Z' (held-out probability, by fitting D=ZA)\n",
      "\n",
      "look at topic similarity between A and A' based on hungarian bipartite matching/L1 difference\n",
      "\n",
      "-----\n",
      "\n",
      "And then look at topic similarity between As from online medical forum and EHRs (without cross validation?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def held_out_probability(D,A):\n",
      "    \n",
      "    def mfunc(x):\n",
      "        return np.dot(x,A) - D\n",
      "\n",
      "    def func(x, sign=1.0):\n",
      "        return np.linalg.norm(mfunc(x), ord='fro')\n",
      "\n",
      "    cons = ({'type' : 'eq',\n",
      "            'fun' : lambda x: np.array([sum(x) - 1]),\n",
      "            'jac' : lambda x: np.array([1] * x.size)},\n",
      "            {'type' : 'eq',\n",
      "             'fun' : lambda x: np.array([sum(x < 0)]),\n",
      "             'jac' : lambda x: np.array([1] * x.size)})\n",
      "\n",
      "    n = A[:,0].size\n",
      "    x0 = np.array([1./n]*n)\n",
      "\n",
      "    res = scipy.optimize.minimize(func, x0, constraints=cons)\n",
      "\n",
      "    return np.linalg.norm(mfunc(res.x), ord='fro')**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def hungarian_bipartite_matching(A, A_prime):\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def L1_difference(A, A_prime):\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dot_pair(A, A_prime):\n",
      "    return np.linalg.norm(np.dot(A, A_prime))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Params:\n",
      "\n",
      "    def __init__(self, filename):\n",
      "        self.log_prefix=None\n",
      "        self.checkpoint_prefix=None\n",
      "        self.seed = int(time.time())\n",
      "\n",
      "        for l in file(filename):\n",
      "            if l == \"\\n\" or l[0] == \"#\":\n",
      "                continue\n",
      "            l = l.strip()\n",
      "            l = l.split('=')\n",
      "            if l[0] == \"log_prefix\":\n",
      "                self.log_prefix = l[1]\n",
      "            elif l[0] == \"max_threads\":\n",
      "                self.max_threads = int(l[1])\n",
      "            elif l[0] == \"eps\":\n",
      "                self.eps = float(l[1])\n",
      "            elif l[0] == \"checkpoint_prefix\":\n",
      "                self.checkpoint_prefix = l[1]\n",
      "            elif l[0] == \"new_dim\":\n",
      "                self.new_dim = int(l[1])\n",
      "            elif l[0] == \"seed\":\n",
      "                self.seed = int(l[1])\n",
      "            elif l[0] == \"anchor_thresh\":\n",
      "                self.anchor_thresh = int(l[1])\n",
      "            elif l[0] == \"top_words\":\n",
      "                self.top_words = int(l[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Q_matrix import generate_Q_matrix \n",
      "import gram_schmidt_convhull_v2 as gs\n",
      "import gram_schmidt_stable as gss\n",
      "from fastRecover import do_recovery\n",
      "\n",
      "def cross_validation(data, var, n_folds=10, n_anchors=5, anchor_tresh=20, settings_file=\"\"):\n",
      "    \n",
      "    params = Params(settings_file)\n",
      "    m,n = data.shape\n",
      "    \n",
      "    # 10 fold cross validation\n",
      "    kf = cross_validation.KFold(m, n_folds=n_folds)\n",
      "    \n",
      "    # for each fold:\n",
      "    for train, test in kf:\n",
      "        \n",
      "        # take the training data \n",
      "        data_train = data[train]\n",
      "        \n",
      "        # build up the Q matrix and variance\n",
      "        train_Q = generate_Q_matrix(data_train)\n",
      "        var_train = calc_var(data_train)\n",
      "        train_Q_bar, var_train = normalize_q(data_train, var_train)\n",
      "        \n",
      "        candidates = get_candidates(train_Q, anchor_thresh)\n",
      "        \n",
      "        # choose anchors based on Arora\n",
      "        gss_anchors, gss_anchor_indices = gss.Projection_Find(train_Q_bar, n_anchors, candidates)\n",
      "        gss_A, gss_topic_likelihoods, gss_R = do_recovery(train_Q, gss_anchors, 'L2', params)\n",
      "        \n",
      "        # choose anchors based on new\n",
      "        gs_anchors, gs_anchor_indices = gs.Projection_Find(train_Q_bar, n_anchors, candidates, var_train)\n",
      "        gs_A, gs_topic_likelihoods, gs_R = do_recovery(train_Q, gs_anchors, 'L2', params)\n",
      "        # TODO!!!!! GET THE PARAMS\n",
      "        \n",
      "        # then use the test data D\n",
      "        data_test = data[test]\n",
      "        \n",
      "        # build up Q matrix\n",
      "        test_Q = generate_Q_matrix(data_test)\n",
      "        test_Q_bar = normalize_q(test_Q)\n",
      "        \n",
      "        # likelihood of the data given A, A'\n",
      "            # find Z and Z' , fitting D=ZA\n",
      "        gss_Z = held_out_probability(D, gss_A)\n",
      "        gs_z = held_out_probability(D, gs_A)\n",
      "        # TODO: how do you check the difference between these??\n",
      "        \n",
      "        # look at topic similarity based on A and A'\n",
      "        topic_sim = dot_pair(gss_A, gs_A)\n",
      "            # topic similarity based on hungarian bipartite\n",
      "            # L1 difference\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize_q(Q, var):\n",
      "    \n",
      "    Q_bar = np.zeros(Q.shape)\n",
      "    \n",
      "    row_sums = Q.sum(1)\n",
      "    for i in xrange(len(Q[:,0])):\n",
      "        Q_bar[i,:] = Q[i,:]/float(row_sums[i])\n",
      "        var[i,:] = var[i,:]/float(row_sums[i])\n",
      "    \n",
      "    return Q_bar, var"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_candidates(Q, anchor_thresh):\n",
      "\n",
      "    candidate_anchors = []\n",
      "    for i in xrange(Q.shape[0]):\n",
      "        if len(np.nonzero(M[i,:])[1]) > anchor_thresh:\n",
      "            candidate_anchors.append(i)\n",
      "    \n",
      "    return candidate_anchors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}